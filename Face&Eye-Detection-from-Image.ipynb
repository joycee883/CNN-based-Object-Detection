{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üë§ **Face and Eye Detection Using OpenCV**\n",
    "\n",
    "This notebook demonstrates real-time face and eye detection using OpenCV's Haar Cascade classifiers. The code includes:\n",
    "1. Static image face and eye detection.\n",
    "2. Real-time face and eye detection using a webcam.\n",
    "\n",
    "---\n",
    "\n",
    "### üì• **Import Required Libraries**\n",
    "\n",
    "We'll begin by importing OpenCV and NumPy, which are essential for handling image data and performing computer vision tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2  # OpenCV for image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå **Step 1: Load and Apply Face Detection on a Static Image**\n",
    "\n",
    "We will load a static image, convert it to grayscale, and use the `haarcascade_frontalface_default.xml` classifier to detect faces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the face classifier with the Haar Cascade XML file for frontal face detection\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the image and convert it to grayscale\n",
    "image = cv2.imread('Task1.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the grayscale image\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# Check if any faces were detected\n",
    "if len(faces) == 0:\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# Draw rectangles around detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (127, 0, 255), 2)\n",
    "\n",
    "# Display the final image with detected face\n",
    "cv2.namedWindow('Face Detection', cv2.WINDOW_NORMAL)  # Allow window resizing\n",
    "cv2.imshow('Face Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìÇ Load Face Classifier:** Initialized the face classifier using Haar Cascade for frontal face detection. <br>\n",
    "\n",
    "**üñºÔ∏è Load and Convert Image:** Loaded the image (Task1.jpg) and converted it to grayscale for better processing. <br>\n",
    "\n",
    "**üîç Detect Faces:** Used detectMultiScale on the grayscale image to locate face regions. <br>\n",
    "\n",
    "**‚úÖ Check for Detection:** Verified if any faces were detected; if none, displayed \"No faces found\". <br>\n",
    "\n",
    "**üñåÔ∏è Draw Bounding Boxes:** For each detected face, drew a rectangle around it on the image. <br>\n",
    "\n",
    "**üëÄ Display Output:** Displayed the image with detected face(s) in a resizable window, awaiting a key press before closing. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå **Step 2: Detecting Faces and Eyes in a Static Image**\n",
    "\n",
    "In this step, we enhance our detection by also identifying eyes within each detected face region. We use the `haarcascade_eye.xml` classifier for eye detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "\n",
    "# Load the face and eye classifiers\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "# Load the image and convert it to grayscale\n",
    "img = cv2.imread('Task6.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the grayscale image\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# Check if faces were found\n",
    "if len(faces) == 0:\n",
    "    print(\"No Face Found\")\n",
    "else:\n",
    "    # For each detected face, detect eyes within the face region\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (127, 0, 255), 2)\n",
    "        \n",
    "        # Define the Region of Interest (ROI) for the face in grayscale and color images\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        # Detect eyes within the face region\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        \n",
    "        # Draw a rectangle around each detected eye\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (255, 255, 0), 2)\n",
    "\n",
    "# Display the final image with detected faces and eyes\n",
    "cv2.namedWindow('Face and Eye Detection', cv2.WINDOW_NORMAL)  # Allow window resizing\n",
    "cv2.imshow('Face and Eye Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üì• Import Libraries:** Loaded OpenCV for image processing. <br>\n",
    "\n",
    "**üìÇ Load Classifiers:** Loaded Haar Cascade classifiers for face and eye detection. <br>\n",
    "\n",
    "**üñºÔ∏è Process Image:** Loaded Task6.png, converted it to grayscale. <br>\n",
    "\n",
    "**üîç Detect Faces and Eyes:** Detected faces, then looked for eyes within each detected face. <br>\n",
    "\n",
    "**üî≤ Draw Rectangles:** Drew rectangles around each detected face and eye. <br>\n",
    "\n",
    "**üëÄ Display Image:** Showed the final image with detected features, then closed on key press. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå **Step 3: Real-Time Face and Eye Detection**\n",
    "\n",
    "This section performs real-time face and eye detection using a webcam. The `face_detector` function detects faces and eyes within a continuous video feed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classifiers for face and eye detection\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "# Define a function for face detection, including padding for better visualization\n",
    "def face_detector(img, size=0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img\n",
    "    \n",
    "    # For each detected face, detect and draw rectangles around the eyes\n",
    "    for (x, y, w, h) in faces:\n",
    "        x = x - 50\n",
    "        w = w + 50\n",
    "        y = y - 50\n",
    "        h = h + 50\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        \n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 0, 255), 2)\n",
    "    \n",
    "    # Flip the output for better alignment with webcam viewing\n",
    "    return cv2.flip(img, 1)\n",
    "\n",
    "# Capture video feed from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Real-Time Face and Eye Detection', face_detector(frame))\n",
    "    if cv2.waitKey(1) == 13:  # Break on Enter key\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìÇ Load Classifiers:** Initialized Haar Cascades for face and eye detection. <br>\n",
    "\n",
    "**üîß Define Detection Function:** Created face_detector function to detect faces with padding for better visualization. <br>\n",
    "\n",
    "**üîç Face and Eye Detection:** <br>\n",
    "\n",
    "    Converted input to grayscale for detection. <br>\n",
    "    Detected faces, added padding around the bounding box. <br>\n",
    "    Drew a blue rectangle around each face. <br>\n",
    "    For each face, detected and drew red rectangles around the eyes. <br>\n",
    "\n",
    "**‚ÜîÔ∏è Flip Output:** Flipped the image horizontally for a more natural, webcam-like view. <br>\n",
    "\n",
    "**üì∑ Real-Time Video Feed:** Captured video from the webcam and applied the face_detector function to each frame. <br>\n",
    "\n",
    "**üõë Exit on Enter Key:** Closed the window and released resources when the Enter key was pressed. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ **Summary**\n",
    "\n",
    "In this notebook, we:\n",
    "1. Detected faces and eyes in a static image.\n",
    "2. Performed real-time face and eye detection using a webcam feed.\n",
    "\n",
    "These techniques provide a foundation for more advanced face recognition and analysis applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
