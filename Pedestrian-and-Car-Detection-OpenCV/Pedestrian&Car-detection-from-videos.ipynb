{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš¶â€â™‚ï¸ Pedestrian and Vehicle Detection using OpenCV ğŸš—\n",
    "\n",
    "## ğŸ“œ Project Overview\n",
    "\n",
    "This project demonstrates **real-time pedestrian and vehicle detection** using **Haar Cascade Classifiers** in OpenCV. The system processes video files to detect **pedestrians** (full-body) and **vehicles (cars)**, drawing bounding boxes around the detected objects.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Pedestrian Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Importing Libraries ğŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2: OpenCV library used for image and video processing.\n",
    "numpy: Numerical processing library, though not directly used in this part, is often useful in such projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Creating the Body Classifier ğŸ‘£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our body classifier\n",
    "body_classifier = cv2.CascadeClassifier(r'Haarcascades\\haarcascade_fullbody.xml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the pre-trained Haar Cascade classifier for full-body detection. The classifier file (haarcascade_fullbody.xml) is used to identify pedestrians in the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Video Capture Setup ğŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate video capture for video file\n",
    "cap = cv2.VideoCapture('Car&Pedestrian Detection Inputs/walking.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Capture is initialized using a video file (walking.avi). The cv2.VideoCapture() function captures frames from the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Processing Each Frame ğŸ”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        break  # Exit loop if frame is not successfully read\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Pass frame to our body classifier\n",
    "    bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\n",
    "    \n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x, y, w, h) in bodies:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "    \n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Pedestrians', frame)\n",
    "\n",
    "    # Break loop on Enter key\n",
    "    if cv2.waitKey(1) == 13:  # 13 is the Enter Key\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close display windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SummaryğŸ¯\n",
    "\n",
    "**ğŸ”„ Enter the video processing loop:** <br>\n",
    "The program enters a while loop that continues as long as the video is successfully opened (cap.isOpened()) â³. <br>\n",
    "\n",
    "**ğŸ–¼ï¸ Read the next frame from the video:** <br>\n",
    "The cap.read() function attempts to read the next frame of the video ğŸ¬. <br>\n",
    "If the frame is successfully read (ret is True), the frame proceeds to processing âœ”ï¸. <br>\n",
    "\n",
    "**ğŸŒ‘ Convert the frame to grayscale:** <br>\n",
    "The frame is converted to grayscale using cv2.cvtColor() to optimize for the Haar Cascade classifier, which works better on grayscale images âš™ï¸. <br>\n",
    "\n",
    "**ğŸš¶ Detect bodies in the frame:**\n",
    "The grayscale image is passed to the body_classifier.detectMultiScale() method to detect bodies in the frame ğŸ•µï¸â€â™‚ï¸. <br>\n",
    "This method returns a list of bounding boxes, each represented by (x, y, w, h) coordinates: <br>\n",
    "(x, y): the top-left corner of the bounding box ğŸ“. <br>\n",
    "w, h: the width and height of the bounding box ğŸ“. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ğŸ“ Draw bounding boxes around detected bodies:** <br>\n",
    "For each detected body, a rectangle is drawn around it on the frame using cv2.rectangle() ğŸŸ¨. <br>\n",
    "The rectangle has a yellow color (0, 255, 255) and thickness 2 to highlight detected bodies ğŸŸ¡. <br>\n",
    "\n",
    "**ğŸ‘€ Display the frame with bounding boxes:** <br>\n",
    "The modified frame, with bounding boxes around detected bodies, is displayed in a window titled \"Pedestrians\" using cv2.imshow() ğŸ–¥ï¸. <br>\n",
    "\n",
    "**âŒ¨ï¸ Wait for user input to exit:** <br>\n",
    "The program waits for key input using cv2.waitKey(1). <br> \n",
    "If the Enter key (ASCII value 13) is pressed, the loop breaks, and the program terminates ğŸ›‘. <br>\n",
    "\n",
    "**ğŸ”š Release video capture object and close windows:** <br>\n",
    "The video capture object cap is released using cap.release() to free system resources ğŸ’¾. <br>\n",
    "Any OpenCV display windows are closed using cv2.destroyAllWindows() ğŸªŸ. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Car Detection\n",
    "### 2.1. Importing Libraries Again ğŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same libraries are imported, along with time to control the frame rate.\n",
    "\n",
    "### 2.2. Creating the Car Classifier ğŸš—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our car classifier\n",
    "car_classifier = cv2.CascadeClassifier(r'Haarcascades\\haarcascade_car.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier (haarcascade_car.xml) is used for detecting cars in the video.\n",
    "\n",
    "### 2.3. Video Capture Setup for Car Video ğŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate video capture for video file\n",
    "cap = cv2.VideoCapture('Car&Pedestrian Detection Inputs/cars.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separate video (cars.avi) is used for car detection.\n",
    "\n",
    "### 2.4. Processing Each Frame for Car Detection ğŸ”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    \n",
    "    time.sleep(.05)\n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "    # Pass frame to our car classifier\n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        cv2.imshow('Cars', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ğŸ¥ Start processing the video:** <br>\n",
    "The code enters a loop that runs as long as the video capture object (cap) is open (cap.isOpened()). <br>\n",
    "\n",
    "**â²ï¸ Introduce a short delay:** <br>\n",
    "time.sleep(.05) introduces a brief 50-millisecond delay â³, slowing down the processing rate for each frame. <br>\n",
    "\n",
    "**ğŸ–¼ï¸ Read the current frame:** <br>\n",
    "ret, frame = cap.read() reads the next frame from the video ğŸ¬. <br>\n",
    "ret is a boolean indicating if the frame was successfully read, and frame contains the frame data. <br>\n",
    "\n",
    "**ğŸŒ‘ Convert the frame to grayscale:** <br>\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) converts the frame to grayscale ğŸ–¤, which is necessary for the car classifier. <br>\n",
    "\n",
    "**ğŸš— Detect cars in the frame:** <br>\n",
    "cars = car_classifier.detectMultiScale(gray, 1.4, 2) uses the car_classifier (a Haar Cascade classifier trained for car detection) to find cars in the frame ğŸš˜. <br>\n",
    "The 1.4 scaling factor allows it to detect cars at various distances, while 2 helps improve detection accuracy. <br>\n",
    "\n",
    "**ğŸ“ Draw bounding boxes around detected cars:** <br>\n",
    "For each detected car (coordinates (x, y, w, h)), a bounding box ğŸŸ¨ is drawn using cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2). <br>\n",
    "\n",
    "**ğŸ‘ï¸ Display the frame with bounding boxes:** <br>\n",
    "cv2.imshow('Cars', frame) displays the frame with bounding boxes around detected cars in a window titled \"Cars\" ğŸ–¥ï¸. <br>\n",
    "\n",
    "**ğŸ”‘ Exit loop on pressing Enter:** <br>\n",
    "if cv2.waitKey(1) == 13 checks for key input and breaks the loop if the Enter key (ASCII code 13) is pressed ğŸ”š. <br>\n",
    "\n",
    "**ğŸ›‘ Release video capture and close windows:** <br>\n",
    "cap.release() releases the video capture resources ğŸ’¾. <br>\n",
    "cv2.destroyAllWindows() closes all OpenCV display windows that were opened ğŸªŸ. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Conclusion ğŸ¯\n",
    "In this project, we used Haar Cascade classifiers for real-time pedestrian and car detection in video files. By processing each frame, converting it to grayscale, and using pre-trained classifiers, we successfully highlighted detected bodies and cars with bounding boxes. This technique can be further enhanced by experimenting with different classifier files or using deep learning-based methods for improved accuracy.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
